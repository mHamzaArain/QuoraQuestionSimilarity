{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1971bf34-2219-4c81-a52e-d973020a123e",
   "metadata": {},
   "source": [
    "<h2> 3.6 Featurizing text data with tfidf weighted word-vectors </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64b6831-10b2-415b-a7ae-63efe2729207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "# exctract word2vec vectors\n",
    "# https://github.com/explosion/spaCy/issues/1721\n",
    "# http://landinghub.visualstudio.com/visual-cpp-build-tools\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fcceb89-187b-4a4a-aa1e-4a3e88d96ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85134839-32a5-496d-abb8-490bc400a9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# avoid decoding problems\n",
    "df_data = pd.read_csv(\"data/00_train.csv\")\n",
    "\n",
    "df_data['question1'] = df_data['question1'].apply(lambda x: str(x))\n",
    "df_data['question2'] = df_data['question2'].apply(lambda x: str(x))\n",
    "df_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb06221-942c-448b-bb88-3c90facf21bf",
   "metadata": {},
   "source": [
    "## Checkpoint 1: Applying TFIDF WEIGHT W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ece43fe4-1c08-4140-99ef-2063f6637810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "questions = list(df_data['question1'][:data_points] + df_data['question2'][:data_points])\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase=False, )\n",
    "tfidf.fit_transform(questions)\n",
    "\n",
    "# dict key:word and value:tf-idf score\n",
    "word2tfidf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf8dabb-6e35-4145-8c38-d7d8b9563c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000   6.704115752446321\n",
      "09   8.313553664880422\n",
      "10   5.540964942640641\n",
      "100   6.809476268104148\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for k, v in word2tfidf.items():\n",
    "    if counter == 4:\n",
    "        break\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(k, ' ', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584aa984-bb3b-49d6-921e-efa49987ed51",
   "metadata": {},
   "source": [
    "- After we find TF-IDF scores, we convert each question to a weighted average of word2vec vectors by these scores.\n",
    "- here we use a pre-trained GLOVE model which comes free with \"Spacy\".  https://spacy.io/usage/vectors-similarity\n",
    "- It is trained on Wikipedia and therefore, it is stronger in terms of word semantics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf7c84db-6f86-4d93-aa4b-92fb8c9694bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_vectors_web_lg, which includes over 1 million unique vectors.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tifidf_to_wieghtedW2V(text_df, tfidf_vectors):\n",
    "    vecs = []\n",
    "    # https://github.com/noamraph/tqdm\n",
    "    # tqdm is used to print the progress bar\n",
    "    for ques in tqdm(list(text_df)):\n",
    "        doc = nlp(ques) \n",
    "        # 384 is the number of dimensions of vectors \n",
    "        mean_vec = np.zeros([len(doc), len(doc[0].vector)])\n",
    "        for word in doc:\n",
    "            # word2vec\n",
    "            vec = word.vector\n",
    "            # fetch df score\n",
    "            try:\n",
    "                idf = tfidf_vectors[str(word)]\n",
    "            except:\n",
    "                idf = 0\n",
    "            # compute final vec\n",
    "            mean_vec += vec * idf\n",
    "        mean_vec = mean_vec.mean(axis=0)\n",
    "        vecs.append(mean_vec)\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67d74d9c-a382-4093-88ec-663fd8e9b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['id']=df_data['id'][:data_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "308ef930-d81f-4723-ab00-da0903b1201e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3000/3000 [00:29<00:00, 101.99it/s]\n"
     ]
    }
   ],
   "source": [
    "df['q1_feats_m'] = list(tifidf_to_wieghtedW2V(df_data['question1'][:data_points], word2tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc29e036-a561-4bca-9832-4b18a921e07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3000/3000 [00:27<00:00, 107.99it/s]\n"
     ]
    }
   ],
   "source": [
    "df['q2_feats_m'] =  list(tifidf_to_wieghtedW2V(df_data['question2'][:data_points], word2tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0c4259b-b8ed-42ee-b89e-ee5763815e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in question1 w2v  dataframe : 96\n",
      "Number of features in question2 w2v  dataframe : 96\n"
     ]
    }
   ],
   "source": [
    "df_q1 = pd.DataFrame(df['q1_feats_m'].values.tolist(), index= df.index)\n",
    "df_q2 = pd.DataFrame(df['q2_feats_m'].values.tolist(), index= df.index)\n",
    "\n",
    "print(\"Number of features in question1 w2v  dataframe :\", df_q1.shape[1])\n",
    "print(\"Number of features in question2 w2v  dataframe :\", df_q2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07401c52-20c7-4e56-8089-94f931aa0c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q1['id']=df_data['id']\n",
    "df_q2['id']=df_data['id']\n",
    "result  = df_q1.merge(df_q2, on='id',how='left')\n",
    "result.to_csv(f'models/01_nlp/tfidf_weight_w2v{data_points}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "481ab05f-7112-4431-a0cc-973102928563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 193)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>3_x</th>\n",
       "      <th>4_x</th>\n",
       "      <th>5_x</th>\n",
       "      <th>6_x</th>\n",
       "      <th>7_x</th>\n",
       "      <th>8_x</th>\n",
       "      <th>9_x</th>\n",
       "      <th>...</th>\n",
       "      <th>86_y</th>\n",
       "      <th>87_y</th>\n",
       "      <th>88_y</th>\n",
       "      <th>89_y</th>\n",
       "      <th>90_y</th>\n",
       "      <th>91_y</th>\n",
       "      <th>92_y</th>\n",
       "      <th>93_y</th>\n",
       "      <th>94_y</th>\n",
       "      <th>95_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.161535</td>\n",
       "      <td>-16.883424</td>\n",
       "      <td>27.364944</td>\n",
       "      <td>-2.225619</td>\n",
       "      <td>6.019804</td>\n",
       "      <td>-9.301675</td>\n",
       "      <td>-1.573213</td>\n",
       "      <td>1.481994</td>\n",
       "      <td>-7.730493</td>\n",
       "      <td>-2.612193</td>\n",
       "      <td>...</td>\n",
       "      <td>20.356704</td>\n",
       "      <td>-33.651369</td>\n",
       "      <td>4.493593</td>\n",
       "      <td>-2.982234</td>\n",
       "      <td>-11.982838</td>\n",
       "      <td>12.24958</td>\n",
       "      <td>18.157573</td>\n",
       "      <td>-10.208319</td>\n",
       "      <td>16.406053</td>\n",
       "      <td>12.979552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0_x        1_x        2_x       3_x       4_x       5_x       6_x  \\\n",
       "0  38.161535 -16.883424  27.364944 -2.225619  6.019804 -9.301675 -1.573213   \n",
       "\n",
       "        7_x       8_x       9_x  ...       86_y       87_y      88_y  \\\n",
       "0  1.481994 -7.730493 -2.612193  ...  20.356704 -33.651369  4.493593   \n",
       "\n",
       "       89_y       90_y      91_y       92_y       93_y       94_y       95_y  \n",
       "0 -2.982234 -11.982838  12.24958  18.157573 -10.208319  16.406053  12.979552  \n",
       "\n",
       "[1 rows x 193 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(result.shape)\n",
    "result.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942fbe89-22ec-47b9-ad4d-d45fc310bbc2",
   "metadata": {},
   "source": [
    "## Checkpoint 2: TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89a63c50-dc26-416b-b780-a7f63adbaa72",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'questions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e75dbc3ce44c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtfidf_vect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.000032\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# test_tfidf = tfidf_vect.transform(X_test_tf.Text)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No of Tfidf features'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'questions' is not defined"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(ngram_range=(1,3),max_features=200000,min_df=0.000032)\n",
    "tfidf = tfidf_vect.fit_transform(questions)\n",
    "# test_tfidf = tfidf_vect.transform(X_test_tf.Text)\n",
    "print('No of Tfidf features',len(tfidf_vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "897e5e8b-2372-48f7-8e7e-22f330e9fdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/01_nlp/tfidf3000.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save vectorizer.vocabulary_\n",
    "import joblib\n",
    "joblib.dump(tfidf_vect.vocabulary_, f'models/01_nlp/tfidf{data_points}.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0466dd60-18e7-483f-92a7-29e6912cb08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.sparse import hstack\n",
    "# X_train1 = hstack((X_train_,train_tfidf))\n",
    "# X_test1 = hstack((X_test_tf.values,test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b148f11-f589-4168-803b-598687b7c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale = StandardScaler(with_mean=False)\n",
    "# X_train_sc = scale.fit_transform(X_train1)\n",
    "# X_test_sc = scale.transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72cb928d-b9eb-4afb-a834-562e10440d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "transformer = TfidfTransformer()\n",
    "vec = CountVectorizer(vocabulary= joblib.load('models/01_nlp/tfidf3000.joblib')) \n",
    "tfidf = transformer.fit_transform(vec.fit_transform([\"dfgsd\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0950e0ef-0fdd-4372-8f51-4569458fbfaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>86578</th>\n",
       "      <th>86579</th>\n",
       "      <th>86580</th>\n",
       "      <th>86581</th>\n",
       "      <th>86582</th>\n",
       "      <th>86583</th>\n",
       "      <th>86584</th>\n",
       "      <th>86585</th>\n",
       "      <th>86586</th>\n",
       "      <th>86587</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 86588 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "\n",
       "   86578  86579  86580  86581  86582  86583  86584  86585  86586  86587  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[1 rows x 86588 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = transformer.fit_transform(vec.fit_transform([\"asdfasldkfnasd sdfasfjasdlkasdf asdfasdf\"]))\n",
    "df = pd.DataFrame.sparse.from_spmatrix(tfidf)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "278a5fac-5f6b-4efe-b21d-d60a2029a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(lowercase=False, )\n",
    "tfidf.fit_transform(questions)\n",
    "\n",
    "# dict key:word and value:tf-idf score\n",
    "word2tfidf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ec73fa8-2913-49b3-a713-4d742dbd941f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'idf_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-7703df4ee4ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtransformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/01_nlp/tfidf3000.joblib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mword2tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midf_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'idf_'"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "transformer = TfidfTransformer()\n",
    "vec = CountVectorizer(vocabulary= joblib.load('models/01_nlp/tfidf3000.joblib')) \n",
    "word2tfidf = dict(zip(vec.get_feature_names(), vec.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0215da15-be05-41b7-a20b-825106437ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_vectors_web_lg, which includes over 1 million unique vectors.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tifidf_to_wieghtedW2V(text_df, tfidf_vectors):\n",
    "    vecs = []\n",
    "    # https://github.com/noamraph/tqdm\n",
    "    # tqdm is used to print the progress bar\n",
    "    for ques in tqdm(list(text_df)):\n",
    "        doc = nlp(ques) \n",
    "        # 384 is the number of dimensions of vectors \n",
    "        mean_vec = np.zeros([len(doc), len(doc[0].vector)])\n",
    "        for word in doc:\n",
    "            # word2vec\n",
    "            vec = word.vector\n",
    "            # fetch df score\n",
    "            try:\n",
    "                idf = tfidf_vectors[str(word)]\n",
    "            except:\n",
    "                idf = 0\n",
    "            # compute final vec\n",
    "            mean_vec += vec * idf\n",
    "        mean_vec = mean_vec.mean(axis=0)\n",
    "        vecs.append(mean_vec)\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5aa2ee5-7a4f-44f1-95f0-5561a661a14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 31.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 42.5868373 , -14.43384796,  23.56646349,  -4.58721548,\n",
       "          4.34642098,  -8.28829327,   1.5316028 ,   8.01649164,\n",
       "         -6.30272877,  -5.92579629,  10.23099293,  -7.72317278,\n",
       "         -0.9798522 , -11.35297754, -28.64178765,  17.88679239,\n",
       "         10.47494122,   1.58813325, -25.98949604,   6.16953206,\n",
       "        -15.84814543,  -4.13335568,  -9.93601622,  -9.05970663,\n",
       "          3.77335968, -12.49490783,  21.75930128, -18.87092397,\n",
       "         14.60306701,  12.00374097,  -7.56202748, -24.81611756,\n",
       "         -0.09120483, -11.75074169,   6.90590835,  -6.70017198,\n",
       "         -3.8140227 ,  11.53788067, -12.0932984 ,  29.87197882,\n",
       "         11.38655274,  30.40739807,  -6.07892269,   2.04485524,\n",
       "         -1.92368665, -15.22185927,   0.52148398,   4.04752018,\n",
       "          0.11793567, -21.49267738,  27.52496653,  15.30824181,\n",
       "         -4.38627413,  24.30221075,   0.54014511, -20.28569125,\n",
       "         19.00639492, -14.903054  ,  -1.13469172,  -7.45244232,\n",
       "         12.59973426, -18.95968416,  12.85267642, -15.25173306,\n",
       "         -7.08873967, -10.36549406, -25.48717479, -20.45072128,\n",
       "         10.43072125,  17.45192313,   2.02865022,   4.3978982 ,\n",
       "        -11.80335563, -12.64502123,  -9.38388406, -12.54842299,\n",
       "        -25.25482789,  -2.67798045,  -7.37760989,   4.05158988,\n",
       "          6.81140463,  18.79223168,   2.53808052,  16.27641991,\n",
       "         -6.73105522,  -4.94156049,  18.52249599, -32.95911005,\n",
       "          2.77795863,  -1.93936495, -13.09728864,  11.51465974,\n",
       "         18.24131709, -14.49749792,  13.02038565,  13.35568346])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tifidf_to_wieghtedW2V([\"what is the step by step guide to invest in share market\"], word2tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82689b3f-cc82-4e9f-b862-4d7602e8b36e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
